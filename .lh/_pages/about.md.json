{
    "sourceFile": "_pages/about.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 6,
            "patches": [
                {
                    "date": 1708872973153,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1708878383009,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,60 @@\n+---\r\n+permalink: /\r\n+title: \"\"\r\n+excerpt: \"\"\r\n+author_profile: true\r\n+redirect_from: \r\n+  - /about/\r\n+  - /about.html\r\n+---\r\n+\r\n+{% if site.google_scholar_stats_use_cdn %}\r\n+{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\r\n+{% else %}\r\n+{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\r\n+{% endif %}\r\n+{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\r\n+\r\n+<span class='anchor' id='about-me'></span>\r\n+\r\n+I am currently a Ph.D student at [School of Computer Science, Wuhan University](https://cs.whu.edu.cn/), supervised by [Prof.Zhongyuan Wang](https://cs.whu.edu.cn/info/1019/2495.htm). Previously, I received Bachelor's Degree and Master's Degree at [School of Computer Science, Wuhan University]  under the guidance of [Prof.Hua Zou](https://cs.whu.edu.cn/info/1019/2887.htm) at . \r\n+\r\n+My research interest includes machine learning and deep learning with focus on gait recognition and medical image analysis (image gerneration, disease recognition, and medical treatment planing). I am also instrested in multi-modal learning, long-tailed classification, few-shot learning, and self-supervised learning. Besides, I have some research experience in the field of time series data processing. \r\n+\r\n+\r\n+# 🔥 News\r\n+- *2023.10*: &nbsp;🎉🎉 One papar is accepted by BIBM 2023.  \r\n+- *2023.10*: &nbsp;🎉🎉 One papar is accepted by BIBM 2023.  \r\n+- *2023.06*: &nbsp;🎉🎉 One papar is accepted by MICCAI 2023.  \r\n+- *2022.06*: &nbsp;🎉🎉 One papar is accepted by MICCAI 2022. \r\n+\r\n+# 📝 Publications \r\n+\r\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n+<div class='paper-box-text' markdown=\"1\">\r\n+\r\n+[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\r\n+\r\n+**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n+\r\n+[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\r\n+- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n+</div>\r\n+</div>\r\n+\r\n+- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\r\n+\r\n+# 🎖 Honors and Awards\r\n+- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n+- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n+\r\n+# 📖 Educations\r\n+- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n+- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n+\r\n+# 💬 Invited Talks\r\n+- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n+- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\r\n+\r\n+# 💻 Internships\r\n+- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n\\ No newline at end of file\n"
                },
                {
                    "date": 1708878868203,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,29 +22,37 @@\n My research interest includes machine learning and deep learning with focus on gait recognition and medical image analysis (image gerneration, disease recognition, and medical treatment planing). I am also instrested in multi-modal learning, long-tailed classification, few-shot learning, and self-supervised learning. Besides, I have some research experience in the field of time series data processing. \r\n \r\n \r\n # 🔥 News\r\n+- *2023.12*: &nbsp;🎉🎉 One papar is accepted by Information.  \r\n - *2023.10*: &nbsp;🎉🎉 One papar is accepted by BIBM 2023.  \r\n-- *2023.10*: &nbsp;🎉🎉 One papar is accepted by BIBM 2023.  \r\n - *2023.06*: &nbsp;🎉🎉 One papar is accepted by MICCAI 2023.  \r\n - *2022.06*: &nbsp;🎉🎉 One papar is accepted by MICCAI 2022. \r\n \r\n # 📝 Publications \r\n \r\n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">MICCAI 2023</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n <div class='paper-box-text' markdown=\"1\">\r\n \r\n-[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\r\n+[Incomplete Multimodal Learning for Visual Acuity Prediction After Cataract Surgery Using Masked Self-Attention](https://link.springer.com/chapter/10.1007/978-3-031-43990-2_69)\r\n \r\n-**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n+**Qian Zhou**, Hua Zou, Haifeng Jiang, Yong Wang\r\n \r\n-[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\r\n-- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n+**<font color=blue>MICCAI 2023 (Poster) </font>** \\| [[**Paper**]](https://link.springer.com/chapter/10.1007/978-3-031-43990-2_69)\r\n </div>\r\n </div>\r\n \r\n-- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\r\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">MICCAI 2022</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n+<div class='paper-box-text' markdown=\"1\">\r\n \r\n+[Long-Tailed Multi-label Retinal Diseases Recognition via Relational Learning and Knowledge Distillation](https://link.springer.com/chapter/10.1007/978-3-031-16434-7_68)\r\n+\r\n+**Qian Zhou**, Hua Zou, Zhongyuan Wang\r\n+\r\n+**<font color=blue>MICCAI 2022 (Poster) </font>** \\| [[**Paper**]](https://link.springer.com/chapter/10.1007/978-3-031-16434-7_68)\r\n+</div>\r\n+</div>\r\n+\r\n # 🎖 Honors and Awards\r\n - *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n - *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n \r\n"
                },
                {
                    "date": 1708880272197,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -40,77 +40,30 @@\n **<font color=blue>MICCAI 2023 (Poster) </font>** \\| [[**Paper**]](https://link.springer.com/chapter/10.1007/978-3-031-43990-2_69)\r\n </div>\r\n </div>\r\n \r\n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">MICCAI 2022</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">MICCAI 2023</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n <div class='paper-box-text' markdown=\"1\">\r\n \r\n-[Long-Tailed Multi-label Retinal Diseases Recognition via Relational Learning and Knowledge Distillation](https://link.springer.com/chapter/10.1007/978-3-031-16434-7_68)\r\n+[Incomplete Multimodal Learning for Visual Acuity Prediction After Cataract Surgery Using Masked Self-Attention](https://link.springer.com/chapter/10.1007/978-3-031-43990-2_69)\r\n \r\n-**Qian Zhou**, Hua Zou, Zhongyuan Wang\r\n+**Qian Zhou**, Hua Zou, Haifeng Jiang, Yong Wang\r\n \r\n-**<font color=blue>MICCAI 2022 (Poster) </font>** \\| [[**Paper**]](https://link.springer.com/chapter/10.1007/978-3-031-16434-7_68)\r\n+**<font color=blue>MICCAI 2023 (Poster) </font>** \\| [[**Paper**]](https://link.springer.com/chapter/10.1007/978-3-031-43990-2_69)\r\n </div>\r\n </div>\r\n \r\n-# 🎖 Honors and Awards\r\n-- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n-- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n-\r\n-# 📖 Educations\r\n-- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n-- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n-\r\n-# 💬 Invited Talks\r\n-- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n-- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\r\n-\r\n-# 💻 Internships\r\n-- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n----\r\n-permalink: /\r\n-title: \"\"\r\n-excerpt: \"\"\r\n-author_profile: true\r\n-redirect_from: \r\n-  - /about/\r\n-  - /about.html\r\n----\r\n-\r\n-{% if site.google_scholar_stats_use_cdn %}\r\n-{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\r\n-{% else %}\r\n-{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\r\n-{% endif %}\r\n-{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\r\n-\r\n-<span class='anchor' id='about-me'></span>\r\n-\r\n-I am currently a Ph.D student at [School of Computer Science, Wuhan University](https://cs.whu.edu.cn/), supervised by [Prof.Zhongyuan Wang](https://cs.whu.edu.cn/info/1019/2495.htm). I received my master degree under the guidance of [Prof.Hua Zou](https://cs.whu.edu.cn/info/1019/2887.htm). \r\n-\r\n-My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src=\"https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations\"></a>).\r\n-\r\n-\r\n-# 🔥 News\r\n-- *2022.02*: &nbsp;🎉🎉 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n-- *2022.02*: &nbsp;🎉🎉 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n-\r\n-# 📝 Publications \r\n-\r\n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">MICCAI 2022</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n <div class='paper-box-text' markdown=\"1\">\r\n \r\n-[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\r\n+[Long-Tailed Multi-label Retinal Diseases Recognition via Relational Learning and Knowledge Distillation](https://link.springer.com/chapter/10.1007/978-3-031-16434-7_68)\r\n \r\n-**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n+**Qian Zhou**, Hua Zou, Zhongyuan Wang\r\n \r\n-[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\r\n-- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n+**<font color=blue>MICCAI 2022 (Poster) </font>** \\| [[**Paper**]](https://link.springer.com/chapter/10.1007/978-3-031-16434-7_68)\r\n </div>\r\n </div>\r\n \r\n-- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\r\n-\r\n # 🎖 Honors and Awards\r\n - *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n - *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n \r\n"
                },
                {
                    "date": 1708880378544,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -29,16 +29,16 @@\n - *2022.06*: &nbsp;🎉🎉 One papar is accepted by MICCAI 2022. \r\n \r\n # 📝 Publications \r\n \r\n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">MICCAI 2023</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">BIBM 2023</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n <div class='paper-box-text' markdown=\"1\">\r\n \r\n-[Incomplete Multimodal Learning for Visual Acuity Prediction After Cataract Surgery Using Masked Self-Attention](https://link.springer.com/chapter/10.1007/978-3-031-43990-2_69)\r\n+[RHViT: A Robust Hierarchical Transformer for 3D Multimodal Brain Tumor Segmentation Using Biased Masked Image Modeling Pre-training](https://ieeexplore.ieee.org/abstract/document/10385746/)\r\n \r\n-**Qian Zhou**, Hua Zou, Haifeng Jiang, Yong Wang\r\n+**Qian Zhou**, Hua Zou, Fei Luo, Yishi Qiu\r\n \r\n-**<font color=blue>MICCAI 2023 (Poster) </font>** \\| [[**Paper**]](https://link.springer.com/chapter/10.1007/978-3-031-43990-2_69)\r\n+**<font color=blue>MICCAI 2023 (Poster) </font>** \\| [[**Paper**]](https://ieeexplore.ieee.org/abstract/document/10385746/)\r\n </div>\r\n </div>\r\n \r\n <div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">MICCAI 2023</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n"
                },
                {
                    "date": 1708880384717,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -36,9 +36,9 @@\n [RHViT: A Robust Hierarchical Transformer for 3D Multimodal Brain Tumor Segmentation Using Biased Masked Image Modeling Pre-training](https://ieeexplore.ieee.org/abstract/document/10385746/)\r\n \r\n **Qian Zhou**, Hua Zou, Fei Luo, Yishi Qiu\r\n \r\n-**<font color=blue>MICCAI 2023 (Poster) </font>** \\| [[**Paper**]](https://ieeexplore.ieee.org/abstract/document/10385746/)\r\n+**<font color=blue>BIBM 2023 (Poster) </font>** \\| [[**Paper**]](https://ieeexplore.ieee.org/abstract/document/10385746/)\r\n </div>\r\n </div>\r\n \r\n <div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">MICCAI 2023</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n"
                },
                {
                    "date": 1708880654349,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -29,8 +29,19 @@\n - *2022.06*: &nbsp;🎉🎉 One papar is accepted by MICCAI 2022. \r\n \r\n # 📝 Publications \r\n \r\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">Information Fusion</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n+<div class='paper-box-text' markdown=\"1\">\r\n+\r\n+[Uncertainty-aware incomplete multimodal fusion for few-shot Central Retinal Artery Occlusion classification](https://www.sciencedirect.com/science/article/pii/S156625352300516X)\r\n+\r\n+**Qian Zhou**, Ting Chen, Hua Zou, Xuan Xiao\r\n+\r\n+**<font color=blue>Information Fusion </font>** \\| [[**Paper**]](https://www.sciencedirect.com/science/article/pii/S156625352300516X)\r\n+</div>\r\n+</div>\r\n+\r\n <div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">BIBM 2023</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n <div class='paper-box-text' markdown=\"1\">\r\n \r\n [RHViT: A Robust Hierarchical Transformer for 3D Multimodal Brain Tumor Segmentation Using Biased Masked Image Modeling Pre-training](https://ieeexplore.ieee.org/abstract/document/10385746/)\r\n@@ -62,18 +73,18 @@\n **<font color=blue>MICCAI 2022 (Poster) </font>** \\| [[**Paper**]](https://link.springer.com/chapter/10.1007/978-3-031-16434-7_68)\r\n </div>\r\n </div>\r\n \r\n-# 🎖 Honors and Awards\r\n+<!-- # 🎖 Honors and Awards\r\n - *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n-- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n+- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->\r\n \r\n # 📖 Educations\r\n - *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n-- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n+- *2017.09 - 2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n \r\n-# 💬 Invited Talks\r\n+<!-- # 💬 Invited Talks\r\n - *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n\\ No newline at end of file\n - *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\r\n \r\n # 💻 Internships\r\n-- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n+- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->\n\\ No newline at end of file\n"
                }
            ],
            "date": 1708872973153,
            "name": "Commit-0",
            "content": "---\r\npermalink: /\r\ntitle: \"\"\r\nexcerpt: \"\"\r\nauthor_profile: true\r\nredirect_from: \r\n  - /about/\r\n  - /about.html\r\n---\r\n\r\n{% if site.google_scholar_stats_use_cdn %}\r\n{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\r\n{% else %}\r\n{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\r\n{% endif %}\r\n{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\r\n\r\n<span class='anchor' id='about-me'></span>\r\n\r\nI am currently a Ph.D student at [School of Computer Science, Wuhan University](https://cs.whu.edu.cn/), supervised by [Prof.Zhongyuan Wang](https://cs.whu.edu.cn/info/1019/2495.htm). I received my master degree under the guidance of [Prof.Hua Zou](https://cs.whu.edu.cn/info/1019/2887.htm). \r\n\r\nMy research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src=\"https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations\"></a>).\r\n\r\n\r\n# 🔥 News\r\n- *2022.02*: &nbsp;🎉🎉 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n- *2022.02*: &nbsp;🎉🎉 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n\r\n# 📝 Publications \r\n\r\n<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\r\n<div class='paper-box-text' markdown=\"1\">\r\n\r\n[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\r\n\r\n**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n\r\n[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\r\n- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n</div>\r\n</div>\r\n\r\n- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\r\n\r\n# 🎖 Honors and Awards\r\n- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n\r\n# 📖 Educations\r\n- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n\r\n# 💬 Invited Talks\r\n- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \r\n- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\r\n\r\n# 💻 Internships\r\n- *2019.05 - 2020.02*, [Lorem](https://github.com/), China."
        }
    ]
}